---
title: 基于 MCP 的审计 Agent 实现
date: 2025-6-24
permalink: /pages/aecc6a/
author: 
  name: Arkrypto
  link: https://github.com/Arkrypto
---

## 静态代码分析概述

### 什么是 SCA

静态代码分析（Static Code Analysis），是指在不运行程序的前提下，对源代码或中间代码（如字节码）进行分析，以发现潜在的问题、缺陷、漏洞或优化点

检查范围

| 检查维度       | 示例                                             |
| -------------- | ------------------------------------------------ |
| ✅ 语法错误     | 拼写错误、漏掉分号、类型不匹配                   |
| ⚠️ 代码规范     | 命名不规范、缩进不统一、行过长                   |
| 🐛 潜在 bug     | 空指针、数组越界、死代码、未关闭资源             |
| 🔐 安全漏洞     | SQL 注入、XSS、路径遍历、硬编码密码              |
| 🧊 性能问题     | 重复计算、不必要对象创建                         |
| 🔧 可维护性问题 | 高复杂度、过深嵌套、长方法、循环依赖             |
| 🎯 设计层面     | 依赖反转、违反 SRP/OCP、代码坏味道（code smell） |

常见的静态分析工具

| 语言       | 工具                                                | 简介                                           |
| ---------- | --------------------------------------------------- | ---------------------------------------------- |
| Java       | ✅ [SonarQube](https://www.sonarqube.org/)           | 全面代码质量平台（支持 Web 展示）              |
| Java       | [SpotBugs（FindBugs）](https://spotbugs.github.io/) | 检查字节码，发现 bug 模式                      |
| Java       | PMD                                                 | 检查代码规范、冗余代码                         |
| Java       | Checkstyle                                          | 检查命名、格式、注释规范等                     |
| Python     | pylint / flake8 / mypy                              | 语法检查 + 类型检查                            |
| JavaScript | ESLint                                              | 最广泛使用的前端代码静态分析                   |
| C/C++      | cppcheck / clang-tidy / Coverity                    | 安全漏洞、内存错误分析                         |
| 多语言     | [Semgrep](https://semgrep.dev/)                     | 支持模式匹配式安全规则，可自定义               |
| 多语言     | CodeQL（GitHub）                                    | 类似 SQL 的代码查询语言，GitHub Actions 可集成 |

### 常见场景

在 CI/CD 流程中进行代码审查，例如使用 GitHub、GitLab、Jenkins，将分析工具**集成进你的代码提交或 PR 流程中**，让每次 push 都自动检查代码质量和安全性

安全扫描类库

- SonarQube 安全规则集
- Semgrep 安全规则库
- CodeQL：GitHub 官方推荐，用于查找逻辑型安全问题（如访问控制缺失、注入漏洞）

集成 SonarQube

- 在本地或 CI/CD 中部署 SonarQube Server
- 使用`sonar-scanner`或 Maven 插件上传代码分析结果
- 可通过浏览器查看：bugs、code smells、安全漏洞、重复代码等

或者在开发过程中使用插件进行代码检查

| 工具       | 集成方式                                |
| ---------- | --------------------------------------- |
| Checkstyle | IDE 插件或 Maven 插件（自动 fail 构建） |
| SpotBugs   | Maven 插件 / Gradle 插件                |
| PMD        | IDE 插件或`mvn pmd:check`               |

### 分析的底层逻辑

静态分析的底层，其实就像编译器的前端（语法分析 ➜ 抽象语法树 ➜ 语义检查 ➜ 流程分析）

```
源代码
  ↓
词法分析（Lexer）
  ↓
语法分析（Parser）→ 抽象语法树 AST
  ↓
语义分析（类型推断、符号绑定）
  ↓
控制流分析（CFA）& 数据流分析（DFA）
  ↓
规则匹配（Lint）或模式匹配（如 Semgrep、CodeQL）
  ↓
输出警告 / 错误 / 报告
```

1️⃣ 词法分析（Lexical Analysis）

把源码分割成一串 token（关键词、标识符、括号、分号等），例如

```java
int x = 5;
```

会被分割成：`int`, `x`, `=`, `5`, `;`

2️⃣ 语法分析（Syntax Analysis）

- 基于上下文无关文法（CFG），将 token 结构化成抽象语法树（AST）
- AST 是“源代码的结构表示”，也是大部分静态分析的核心入口

例如代码：`if (x > 0) y = 1;`）

```java
IfStatement
 ├─ Condition: BinaryExpr (x > 0)
 └─ Then: AssignExpr (y = 1)
```

工具如 ESLint、Checkstyle、PMD、SpotBugs 都会用 AST

3️⃣ 语义分析（Semantic Analysis）

检查变量类型、作用域、是否定义、调用合法性等，例如

```java
x = y + 1;  // 如果 y 没有定义，报错
```

4️⃣ 控制流分析（Control Flow Analysis, CFA）

- 构建控制流程图（CFG），分析条件/循环/分支/跳转
- 用来判断代码是否可达、分支覆盖是否完整等

图示

```css
[Start]
   ↓
[x > 0] ─ Yes → [doSomething()]
   └─ No → [return]
```

5️⃣ 数据流分析（Data Flow Analysis, DFA）

- 分析变量的定义-使用链、是否初始化、是否为空等
- 举例：空指针分析、资源未关闭、变量未赋值就使用等，SpotBugs 等工具广泛应用

6️⃣ 规则匹配 / 模式识别（Pattern Matching）

- 使用预定义或用户自定义的规则集来匹配代码结构
- 如 Checkstyle 会检查 `class 命名必须大写开头`，PMD 会匹配 `== null` 的代码块
- Semgrep/CodeQL 更强，它可以匹配结构+上下文

```yaml
rules:
  - id: detect-hardcoded-password
    pattern: |
      password = "..."
```

模式匹配 + AST 导航是现代分析工具（如 Semgrep、CodeQL）的重要特性

一些更智能的方法

| 方法                                | 说明                                                         |
| ----------------------------------- | ------------------------------------------------------------ |
| 符号执行（Symbolic Execution）      | 把变量当成符号而不是具体值进行逻辑推演，用于路径覆盖         |
| 抽象解释（Abstract Interpretation） | 对程序执行进行近似建模，保守地发现问题                       |
| 模型检测（Model Checking）          | 建模程序状态机，验证其是否满足规范（如死锁）                 |
| 人工智能辅助分析                    | 结合语言模型，自动修复警告或生成规则（GitHub Copilot + CodeQL） |

### Java 词法分析器

基于 Java 实现，参考

- [Java语言的词法分析器的Java实现 - daheww - 博客园](https://www.cnblogs.com/daheww/p/13873618.html)
- [词法和语法分析器设计 | Arkrypto](http://arkrypto.github.io/pages/c78d5b/#词法分析器-lexer)

保留关键字

```java
public class Lexical {
    private static final String reserveWords[] = { "abstract", "boolean", "break", "byte", "case", "catch", "char", "class", "continue", "default", "do", "double", "else", "extends", "final", "finally", "float", "for", "if", "implements", "import", "instanceof", "int", "interface", "long", "native", "new", "package", "private", "protected", "public", "return", "short", "static", "super", "switch", "synchronized", "this", "throw", "throws", "transient", "try", "void", "volatile", "while", "strictfp", "enum", "goto", "const", "assert"     }; // 50
}
```

初始化以及构造函数

```java
public class Lexical {
    private BufferedReader fd;
    private int state; // 当前状态
    private char ch; // 当前字符
    private String info; // 结果串
    private String temp; // 临时存储
    int lineNum; // 当前代码行数
    boolean finished; // 判断文件是否读完
    
    public Lexical() {
        info = "";
        temp = "";
        lineNum = 1;
        finished = false;
        getChar();
        analyze(); // 分析
        write(info); // 输出
    }
}
```

输入输出，状态转移

```java
private void getChar() {
    try {
        if (fd == null) {
            ClassPathResource resource = new ClassPathResource("test.txt");
            fd = new BufferedReader(new InputStreamReader(resource.getInputStream()));
        }
        int end = fd.read();
        if (end == -1) { // 当从一个文件中读取数据时，在数据最后会返回一个int型-1来表示结束
            fd.close();
            finished = true;
            return;
        }
        ch = (char) end;
    } catch (IOException e) {
        e.printStackTrace();
    }
}

private void toNextCharAndChangeState(int state) {
    this.state = state;
    getChar();
}

private void toNextCharAndStoreTempAndChangeState(int state) {
    temp += ch;
    this.state = state;
    getChar();
}

private void writeInfo(String value, String type) {
    info += lineNum + ": < " + type + " , " + value + " >;\r\n";
    state = 0;
}

private void write(String info) {
    try {
        FileWriter fw = new FileWriter("result.txt");
        fw.write(info);
        fw.flush(); // 刷新数据，将数据写入文件中
        fw.close();
    } catch (IOException e) {
        e.printStackTrace();
    }
}

private void error(int i) {
    info = "词法分析出错\r\n错误定位：" + i;
}
```

一些辅助的判断函数

```java
private boolean isReserve(String temp2) {
    for (int i = 0; i < 50; i++) {
        if (temp.equals(reserveWords[i])) {
            return true;
        }
    }
    return false;
}

private boolean isLegalChar(String temp) {
    char[] ch = temp.toCharArray();
    int length = ch.length;
    boolean isLegalChar = false;
    
    if (length == 2) { // ''
        isLegalChar = false;
    } else if (length == 3) {
        isLegalChar = true;
    } else if (length == 4) {
        if ((ch[1] == '\\') && (ch[2] == 'b' || ch[2] == 'n' || ch[2] == 'r' || ch[2] == 't' || ch[2] == '\"'
                                || ch[2] == '\'' || ch[2] == '\\' || isDigital(ch[2]))) {
            isLegalChar = true;
        }
    } else if (length <= 6) {
        if (ch[1] == '\\') {
            for (int i = 2; i < (length - 1); i++) {
                if (!isDigital(ch[i])) {
                    isLegalChar = false;
                    break;
                }
                isLegalChar = true;
            }
        } else {
            System.out.println('*');
            isLegalChar = false;
        }
    } else {
        isLegalChar = false;
    }

    return isLegalChar;
}

private boolean isLetter(char ch) {
    return (ch >= 65 && ch <= 90) || (ch >= 97 && ch <= 122);
}

private boolean isBoundary(char ch) {
    return ch == ',' || ch == ';' || ch == '(' || ch == ')' || ch == '[' || ch == ']' || ch == '{' || ch == '}';
}

private boolean isOperator1(char ch) { // / * = &lt; &gt;
    return ch == '/' || ch == '*' || ch == '=' || ch == '<' || ch == '>';
}

private boolean isOperator2(char ch) { // ? . :
    return ch == '?' || ch == '.' || ch == ':';
}

private boolean isDigital(char ch) {
    return ch >= 48 && ch <= 57;
}
```

analyze 函数：每次处理一个字符

```java
private void analyze() {

    if (finished && temp.equals(""))
        return; // 已经读取到最后一个字符，且没有待处理字符
    if (ch == '\n')
        lineNum++;

    switch (state) {
        case 0 -> {
            temp = "";
            if (ch == ' ' || ch == '\r' || ch == '\t' || ch == '\n') {
                toNextCharAndChangeState(0);
            } else if (ch == '/') {
                toNextCharAndStoreTempAndChangeState(1);
            } else if (isDigital(ch)) {
                toNextCharAndStoreTempAndChangeState(5);
            } else if (isOperator1(ch)) {
                toNextCharAndStoreTempAndChangeState(8);
            } else if (ch == '!') {
                toNextCharAndStoreTempAndChangeState(9);
            } else if (isOperator2(ch)) {
                writeInfo((ch + ""), "运算符");
                getChar();
            } else if (isBoundary(ch)) {
                writeInfo((ch + ""), "界符");
                getChar();
            } else if (ch == '"') {
                toNextCharAndStoreTempAndChangeState(10);
            } else if (isLetter(ch)) {
                toNextCharAndStoreTempAndChangeState(11);
            } else if (ch == '\'') {
                toNextCharAndStoreTempAndChangeState(14);
            } else if (ch == '-' || ch == '+') {
                toNextCharAndStoreTempAndChangeState(16);
            } else if (ch == '|') {
                toNextCharAndStoreTempAndChangeState(17);
            } else if (ch == '&') {
                toNextCharAndStoreTempAndChangeState(18);
            } else if (ch == (char) -1) {
                // 程序应该结束
                return;
            } else { // 非法字符
                error(1);
                return;
            }
        }
        case 1 -> {
            if (ch == '/') {
                toNextCharAndChangeState(2);
            } else if (ch == '*') {
                toNextCharAndChangeState(3);
            } else {
                state = 8;
            }
        }
        case 2 -> { // 处理注释
            if (ch == '\n') {
                state = 0;
                getChar();
            } else {
                getChar();
            }
        }
        case 3 -> { // 处理注释
            if (ch == '*') {
                toNextCharAndChangeState(4);
            } else {
                getChar();
            }
        }
        case 4 -> { // 处理注释
            if (ch == '/') {
                toNextCharAndChangeState(0);
            } else {
                toNextCharAndChangeState(3);
            }
        }
        case 5 -> {
            if (isDigital(ch)) {
                temp += ch;
                getChar();
            } else {
                state = 6;
            }
        }
        case 6 -> {
            if (ch == '.') {
                toNextCharAndStoreTempAndChangeState(7);
            } else {
                writeInfo(temp, "常数");
            }
        }
        case 7 -> {
            if (isDigital(ch)) {
                toNextCharAndStoreTempAndChangeState(13);
            } else {
                error(4);
                return;
            }
        }
        case 8 -> {
            if (ch == '=') {
                temp += ch;
                writeInfo(temp, "运算符");
                getChar();
            } else {
                writeInfo(temp, "运算符");
            }
        }
        case 9 -> {
            if (ch == '=') {
                temp += ch;
                writeInfo(temp, "运算符");
                getChar();
            } else {
                error(2);
                return;
            }
        }
        case 10 -> {
            if (ch == '"') {
                temp += ch;
                writeInfo(temp, "常量");
                getChar();
            } else if (ch == '\\') {
                for (int i = 0; i < 2 ; i++){
                    temp += ch;
                    getChar();
                }
                state = 10;
            } else {
                toNextCharAndStoreTempAndChangeState(10);
            }
        } case 11 -> {
            if (isDigital(ch) || isLetter(ch) || ch == '_') {
                toNextCharAndStoreTempAndChangeState(11);
            } else {
                state = 12;
            }
        }
        case 12 -> {
            if (isReserve(temp)) {
                writeInfo(temp, "保留字");
                getChar();
            } else {
                writeInfo(temp, "标识符");
                getChar();
            }
        }
        case 13 -> {
            if (isDigital(ch)) {
                toNextCharAndStoreTempAndChangeState(13);
            } else {
                writeInfo(temp, "常数");
            }
        }
        case 14 -> {
            if (ch == '\'') {
                temp += ch;
                if (isLegalChar(temp)) {
                    writeInfo(temp, "常量");
                } else {
                    error(9);
                    return;
                }
                getChar();
            } else if (ch == '\\') {
                for (int i = 0; i < 2; i++){
                    temp += ch;
                    getChar();
                }
                state = 14;
            } else {
                toNextCharAndStoreTempAndChangeState(14);
            }
        } case 16 -> {
            if (isDigital(ch)) {
                toNextCharAndStoreTempAndChangeState(5);
            } else {
                state = 8;
            }
        }
        case 17 -> {
            if (ch == '|') {
                temp += ch;
                writeInfo(temp, "运算符");
                getChar();
            } else {
                writeInfo(temp, "运算符");
            }
        }
        case 18 -> {
            if (ch == '&') {
                temp += ch;
                writeInfo(temp, "运算符");
                getChar();
            } else {
                writeInfo(temp, "运算符");
            }
        }
        default -> {
            error(3);
            return;
        }
    }

    analyze(); // 重复调用
}
```

主函数

```java
public class Lexical {
    public static void main(String[] args) throws IOException {
        new Lexical();
    }
}
```

测试输入

```java
private boolean isReserve(String temp2) {
    for (int i = 0; i < 50; i++) {
        if (temp.equals(reserveWords[i])) {
            return true;
        }
    }
    return false;
}
```

输出

```
1: < 保留字 , private >;
1: < 保留字 , boolean >;
1: < 标识符 , isReserve >;
1: < 标识符 , String >;
1: < 标识符 , temp2 >;
1: < 界符 , { >;
2: < 保留字 , for >;
2: < 界符 , ( >;
2: < 保留字 , int >;
2: < 标识符 , i >;
2: < 运算符 , = >;
2: < 常数 , 0 >;
2: < 界符 , ; >;
2: < 标识符 , i >;
2: < 运算符 , < >;
2: < 常数 , 50 >;
2: < 界符 , ; >;
2: < 标识符 , i >;
2: < 运算符 , + >;
2: < 界符 , ) >;
2: < 界符 , { >;
3: < 保留字 , if >;
3: < 界符 , ( >;
3: < 标识符 , temp >;
3: < 标识符 , equals >;
3: < 标识符 , reserveWords >;
3: < 标识符 , i >;
3: < 界符 , ) >;
3: < 界符 , ) >;
3: < 界符 , { >;
4: < 保留字 , return >;
4: < 标识符 , true >;
5: < 界符 , } >;
6: < 界符 , } >;
7: < 保留字 , return >;
7: < 标识符 , false >;
8: < 界符 , } >;
```

## 后端代码分析类库

考虑这样一个场景：对于一个完整的 Spring 项目，我需要按照接口，抽丝剥茧般把每个 API 的底层调用整理成一个完整的依赖链路，而后将每条链路以及相关的源码扔给大模型进行安全性分析

问题的关键在于：如何构建每个 API 调用的依赖路径以及如何整理每条路径上的相关代码

### Java Parser

语法及语义分析

- [JavaParser - Home](https://javaparser.org/)
- [javaparser/javaparser: Java 1-21 Parser and Abstract Syntax Tree for Java with advanced analysis functionalities.](https://github.com/javaparser/javaparser)

核心库及功能

| 名称                 | 功能                                                         |
| -------------------- | ------------------------------------------------------------ |
| `JavaParser`         | 语法分析器，构建 Java 源码的 AST                             |
| `JavaSymbolSolver`   | 做静态符号解析（变量、方法、类之间的引用关系），基于类型信息解析方法调用、变量引用等 |
| `CombinedTypeSolver` | 提供类路径上的类型信息（包括 JRE、项目源码、依赖 jar）       |

Maven 引入

```xml
<dependency>
    <groupId>com.github.javaparser</groupId>
    <artifactId>javaparser-symbol-solver-core</artifactId>
    <version>3.25.5</version>
</dependency>
```

ProjectAnalyzer：分析一个目录下的所有 Java 代码，记录各自的语法树

```java
public class ProjectAnalyzer {
    
    private Map<String, String> pathToSource = new HashMap<>();
    private Map<String, CompilationUnit> pathToAst = new HashMap<>();

    public void analyzeDirectory(File root) {
        File[] files = root.listFiles(f -> f.getName().endsWith(".java"));
        if (files == null) return;

        for (File file : files) {
            try {
                String content = Files.readString(file.toPath());
                pathToSource.put(file.getAbsolutePath(), content);
                CompilationUnit cu = StaticJavaParser.parse(content);
                pathToAst.put(file.getAbsolutePath(), cu);
            } catch (Exception e) {
                System.err.println("Error parsing " + file.getName());
            }
        }
    }

    public Map<String, CompilationUnit> getAstMap() {
        return pathToAst;
    }

    public Map<String, String> getSourceMap() {
        return pathToSource;
    }
}
```

JsonGenerator：将 ProjectAnalyzer 的 AST 记录转化为 String 类型的 Json 数据

我们想获得的数据结构

```java
public class MethodInfo {
    public String methodName;
    public String returnType;
    public List<String> parameters;
    public List<String> calls = new ArrayList<>();
}

public class ClassInfo {
    public String className;
    public List<MethodInfo> methods = new ArrayList<>();
}

```

在遍历 AST 的同时获取信息

```java
import com.github.javaparser.ast.CompilationUnit;
import com.github.javaparser.ast.body.*;
import com.github.javaparser.ast.expr.MethodCallExpr;
import com.google.gson.Gson;
import com.google.gson.GsonBuilder;

import java.util.*;

public class JsonGenerator {

    private final Map<String, CompilationUnit> pathToAst;

    public JsonGenerator(Map<String, CompilationUnit> pathToAst) {
        this.pathToAst = pathToAst;
    }

    public String generateJson() {
        Map<String, Object> output = new HashMap<>();

        for (Map.Entry<String, CompilationUnit> entry : pathToAst.entrySet()) {
            String filePath = entry.getKey();
            CompilationUnit cu = entry.getValue();

            List<ClassInfo> classInfos = new ArrayList<>();

            for (TypeDeclaration<?> type : cu.getTypes()) {
                if (type.isClassOrInterfaceDeclaration()) {
                    ClassOrInterfaceDeclaration clazz = (ClassOrInterfaceDeclaration) type;

                    ClassInfo classInfo = new ClassInfo();
                    classInfo.className = clazz.getNameAsString();

                    for (MethodDeclaration method : clazz.getMethods()) {
                        MethodInfo methodInfo = new MethodInfo();
                        methodInfo.methodName = method.getNameAsString();
                        methodInfo.returnType = method.getTypeAsString();
                        methodInfo.parameters = method.getParameters().stream()
                            .map(p -> p.getTypeAsString() + " " + p.getNameAsString())
                            .toList();

                        // 👇 提取调用的方法
                        method.findAll(MethodCallExpr.class).forEach(call -> {
                            methodInfo.calls.add(call.getNameAsString());
                        });

                        classInfo.methods.add(methodInfo);
                    }

                    classInfos.add(classInfo);
                }
            }

            output.put(filePath, classInfos);
        }

        Gson gson = new GsonBuilder().setPrettyPrinting().create();
        return gson.toJson(output);
    }
}
```

### Language Server

Eclipse JDT Language Server

- [eclipse-jdtls/eclipse.jdt.ls: Java language server](https://github.com/eclipse-jdtls/eclipse.jdt.ls)
- [Eclipse JDT Language Server - manateelazycat/lsp-bridge GitHub Wiki](https://github-wiki-see.page/m/manateelazycat/lsp-bridge/wiki/Eclipse-JDT-Language-Server)

我之前想的是，调整 LS 对源码进行统一标准化的处理，输出 JSON 数据，再一股脑丢给 LLM 分析

- 即用户作为 LS 的 Client
- 这样我的调用关系是：用户 → LS → LLM → 用户

龙导的意思是，让 LLM 作为一个独立客体，通过 CMP 调用 LS 边分析边追溯

- 等于现在变成了：用户 → LLM ↔ LS → 用户
- 此时 LLM 变成了 LS 的 Client，当然这里实际的 Client 是 LLM 调用的 MCP 客体

我直接将源码丢给 LLM，LLM 从根节点开始分析，分析到底层的方法时，采用 MCP 对 LS 进行调用，返回对应的方法名和源码，然后直接跳到那一段代码接着分析，这样会大大提升 LLM 的准度和效率

## Spring MCP 服务构建

### Spring AI



### MCP Server



### MCP Client
