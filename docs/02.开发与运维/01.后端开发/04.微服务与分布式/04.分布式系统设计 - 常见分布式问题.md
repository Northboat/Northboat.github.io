---
date: 2025-02-21 00:00:00
author: 
  name: Arkrypto
  link: https://github.com/Arkrypto
title: 分布式系统设计 - 常见分布式问题
permalink: /pages/4f5b6d/
---

## 常见分布式问题

### 分布式事务

2PC：两阶段提交，将事务的提交过程分为资源准备和资源提交两个阶段，并且由事务协调者来协调所有事务参与者，如果准备阶段所有事务参与者都预留资源成功，则进行第二阶段的资源提交，否则事务协调者回滚资源

3PC：三阶段提交协议，是二阶段提交协议的改进版本，三阶段提交有两个改动点

1. 在协调者和参与者中都引入超时机制
2. 在第一阶段和第二阶段中插入一个准备阶段，保证了在最后提交阶段之前各参与节点的状态是一致的

TCC：一种分布式事务处理方法，它的名称来自于其三个阶段`Try, Confirm, Cancel`，这种方法主要用于处理在分布式系统中，多个服务需要协同完成一项操作时的一致性问题

### 分布式锁

由于要保证分布式系统的性能，分布式锁一般都是乐观锁，与之对应的是悲观锁

悲观锁是将资源锁住，等一个之前获得锁的线程释放锁之后，下一个线程才可以访问。而乐观锁采取了一种宽泛的态度，通过某种方式不加锁来处理资源，比如通过给记录加 version 或 timestamp 来操作数据（比如 CAS 策略），**性能较悲观锁有很大的提高**

- 像 synchronized、Lock、ReadWriteLock 均为悲观锁
- 而原子类例如 AtomicInteger 用的实际上是 CAS 机制，所以是一个乐观锁 → 但是没有引入版本控制，所以会出现 ABA 问题（A→B→A），详见 - [原子性、单例模式和 CAS | 北船](https://northboat.github.io/pages/479c11/#什么是-cas)

还有一种乐观锁的理解：Git

- 我们只有在 push 的时候才会进行锁的检查，返回错误信息
- 无论是 add 还是 commit，都是不上锁的（乐观的默认可执行），碰到问题（push 版本不对）再去解决

当然，我们在此处只讨论分布式锁的实现，需要明确的是，分布式锁既可以是悲观的也可以是乐观的，这要根据具体场景进行设计考量

1️⃣ Redis 实现

Redission，基于 Redis 集群的分布式锁，本质上就是维护同一个键值对，作为 Lock，获取时上锁，获取前检查这个键值对是否有锁，释放时解锁

2️⃣ Zookeeper 实现

订阅发布模式下，多个 Watcher 争用一个临时节点

- 上锁：创建临时节点
- 释放：删除临时节点

### 分布式会话

在分布式系统的诸多后端接口之间维护**唯一**的用户 Session，用以管理用户登陆状态，可以用 Redis 存放用户 Session 并设置有效期实现（在这里，一个 Session 实际上就是一个 KV 对）

使用 Redis 做用户登陆状态管理（分布式会话管理），通常有这样两种做法

1️⃣ Token 为键，用户信息为值，例如

```
Key:   login:token:{jwt-token}
Value: "{userId: u12345}, {username: arkrypto}, {roles: [admin]}, {loginTime: 2025-05-19T18:00:00}"
```

Value 实际上是用户信息的一个 JsonToString

2️⃣ 用户 ID 为键，Token 为值，这个很简单

```
Key:   login:user:{userId}
Value: jwt-token
```

其中，2 适合单点登录（SSO，Single Sign-On）控制，因为可以很轻松的做到一个 ID 对应一个 KV 对，即一个会话；而前者默认支持多端登录

| 项目             | 方式一：以 `token` 为 key | 方式二：以 `userId` 为 key               |
| ---------------- | ------------------------- | ---------------------------------------- |
| Key              | `login:token:{token}`     | `login:user:{userId}`                    |
| Value            | 用户信息（JSON 格式）     | token 字符串                             |
| 是否支持多端登录 | 支持（每个 token 独立）   | 默认不支持（一个 userId 对应一个 token） |
| 用途             | 校验身份和获取用户信息    | 实现单点登录/控制登录唯一性              |
| 删除策略         | 删除 token（用于登出）    | 删除 userId-token 绑定（用于限制）       |

### 分布式 ID

在分布式系统中，要保证 ID 的唯一性，粗糙方案

1. UUID：空间大，无序
2. 数据库自增 ID：性能差，单点故障

较好的方案

1. Redis 自增 ID：多机设置不同初始 ID 和不同步长
2. 雪花算法（Snowflake）
   - 生成 64 位的 ID，包含时间戳、机器 ID 和序列号
   - 高性能、有序，但依赖时钟同步

### 分布式链路追踪

用到再看吧

## 索引与事务

### 索引

在 MySQL 建表是，会对主键（primary key）自动添加索引，实际上就是一个额外的存储主键有序数据结构，采用类似二分搜索的快速规模压缩算法对主键进行检索（实际上是一棵 B+ 树）

这是 B 树：需要保证叶子结点都在同一层

<img src="./assets/e84842ce8a18fb34d9907169bad94a7f.png">

B+ 树在 B 树的基础上

- 把所有的关键字都放在最后一层（叶子层），所有非叶子结点都是“索引”
- 在叶子结点那层加了一个链指针把叶子层连接在一起，可以避免当树规模过大时，搜索效率降低

<img src="./assets/20190813232949316.png">

### 事务

在 Spring 中，可用`@Transactional` 声明事务，它极大地简化了事务管理，直接在 Service 层对应的方法上进行注解，即可完成一次事务的编写

```java
@Deprecated
@Transactional
@Override
public int doWithdrawal(TransactionDTO transactionDTO) {
    int r = accountMapper.updateBalanceById(transactionDTO.getMyAccount(), transactionDTO.getAmount().negate());
    log.info(transactionDTO.toString());
    Transaction transaction = new Transaction(transactionDTO.getMyAccount(),
                                              0L,
                                              transactionDTO.getName(),
                                              "外部账户",
                                              transactionDTO.getAmount(),
                                              "用户取款",
                                              r == 1 ? 0 : 1);
    return transactionMapper.insertTransaction(transaction);
}
```

但在使用时需要注意一些关键点，否则可能导致事务失效或出现意外行为

- `@Transactional` 只能修饰 public 方法
- `@Transactional` 不能自身调用，比如方法 A 和 B 都在 UserService 类中，如果在 A 中调用 B 方法，即使 B 方法有`@Transactional` 修饰，这个事务也不会生效，这和 Java 的动态代理机制有关

设置超时（timeout）：设置事务的超时时间（单位：秒），超过时间未完成则回滚

```java
@Transactional(timeout = 5)
public void methodC() {
    // 事务超时时间为 5 秒
}
```

只读（readOnly）：标记事务为只读，优化数据库性能（如 MySQL 的只读事务会禁用写锁）

- **注意**：只读事务中不能执行写操作，否则会抛出异常

```java
@Transactional(readOnly = true)
public void methodD() {
    // 只读事务
}
```

事务回滚规则：默认情况下，`@Transactional` 回滚的是 RunTimeException，如果需要特殊要求，需要指定

```java
// 回滚 I/O 和 SQL 异常
@Transactional(rollbackFor = {IOException.class, SQLException.class})
// 不回滚空指针异常
@Transactional(noRollbackFor = {NullPointerException.class})
```

### 脏读、不可重复读、幻读和丢失修改

`@Transactional` 的 `isolation` 属性用于定义事务的隔离级别，常见的隔离级别如下

| 隔离级别                         | 防止脏读 | 防止不可重复读 | 防止幻读         |
| -------------------------------- | -------- | -------------- | ---------------- |
| **read uncommitted**             | ✗        | ✗              | ✗                |
| **read committed**               | ✓        | ✗              | ✗                |
| **repeatable read** (MySQL 默认) | ✓        | ✓              | 部分 ✓（间隙锁） |
| **serializable**                 | ✓        | ✓              | ✓                |

```java
@Transactional(isolation = Isolation.REPEATABLE_READ)
public void methodB() {
    // 在可重复读隔离级别下执行
}
```

什么是脏读、不可重复读和幻读？

1️⃣ 脏读：读到了写过程中的临时数据

解决办法：给写加锁，写时不能读

2️⃣ 不可重复读：就是说，在一个事务中，前后重复读同一数据，数据存在改变

原因：读时可写 → 解决办法：给读加锁

3️⃣ 幻读：针对表而言，之前给行加了读/写锁，即单个数据项有读/写锁从而防止脏读和不可重复读，但对于数据表而言，比如`count(*)`操作，即使数据项 a 在被写，数据项 b 在被读，但不影响数据 c 插入数据表，那么同一事务的前后两次`count(*)`就有可能返回不一样的结果，这就叫幻读

解决方法：对整个数据表加读写锁，彻底串行执行，效率极低

4️⃣ 修改丢失：写写没加锁，后一次写覆盖了前一次写的提交，很有可能会破坏数据一致性

例如：存款原本有 1000，A 事务存 50，B 事务取 100，二者进行修改时，都会先读取余额，假设他们现在同时读，都读到 1000，那么 A 会将 1050 写回（操作 ①），B 会将 900 写回（操作 ②），操作 ① ② 先后执行，那么最终存款将会变成 900

这一过程覆盖了 A 事务存款 50 的 commit，并且破坏了数据的一致性

### Seata 实战

## 降级、熔断和限流

### 什么是降级、熔断和限流

降级：服务端出现问题，客户端降级使用 FallbackMethod 方法，返回一个友好的提示，而不至于忙等

熔断：达到一定条件后（比如请求故障率达到 60%），一直降级，缓慢恢复

限流：比如点对点消息队列缓慢消费请求，大家**排队**，一秒钟 N 个，有序进行，秒杀高并发等操作，严禁一窝蜂的过来拥挤

### 熔断实现

> 以前是 Hystrix，现在用 Resilience4J 或者 **Sentinel**

熔断（Circuit Breaker）和限流（Rate Limiting）是分布式系统中**保障服务高可用性和稳定性**的重要手段，主要用于**防止雪崩效应**，确保在高并发场景下系统能平稳运行

- 熔断（Circuit Breaker）类似于**家里的电路保险丝**，当电流过大时，保险丝会断开电路，以防电器损坏。在**分布式系统**中，熔断机制用于**检测服务是否故障，并在故障严重时自动阻止请求，以防止系统崩溃**

熔断器通常有以下**三种状态**

1. 关闭（Closed）：服务正常运行，请求可以自由通过
2. 打开（Open）：当错误率达到阈值，熔断器打开，所有请求都会被拒绝，防止系统继续崩溃
3. 半开（Half-Open）：经过一段时间后，系统尝试放行部分请求进行测试，如果恢复正常，熔断器关闭，否则保持打开状态

Spring Cloud 以前使用 **Hystrix** 作为熔断组件，但现在推荐使用 **Resilience4J**

**1️⃣ 添加依赖**

```xml
<dependency>
    <groupId>io.github.resilience4j</groupId>
    <artifactId>resilience4j-spring-boot2</artifactId>
    <version>1.7.1</version>
</dependency>
```

**2️⃣ 代码示例**

```java
@CircuitBreaker(name = "paymentService", fallbackMethod = "fallbackPayment")
public String callPaymentService() {
    // 调用远程支付服务
    return restTemplate.getForObject("http://payment-service/pay", String.class);
}

// 熔断后的降级方法
public String fallbackPayment(Exception e) {
    return "支付服务不可用，请稍后重试";
}
```

**3️⃣ 配置熔断阈值**

```yaml
resilience4j.circuitbreaker:
  instances:
    paymentService:
      failureRateThreshold: 50  # 失败率达到 50% 时触发熔断
      waitDurationInOpenState: 5000ms  # 熔断后 5 秒再尝试恢复
      permittedNumberOfCallsInHalfOpenState: 3  # 半开状态时允许 3 个请求进行尝试
```

👉 这样，当支付服务失败率超过 50% 时，请求会自动走 `fallbackPayment` 方法，而不会继续尝试访问已故障的支付服务

### 限流实现

> SpringCloud Gateway

限流（Rate Limiting）是一种**限制请求速率**的技术，防止单个服务被过量请求拖垮，确保系统能够平稳运行

为什么需要限流？

- 防止流量暴增导致系统崩溃（如双十一购物、秒杀活动）
- 防止恶意攻击（如爬虫、DDoS 攻击）
- 合理分配系统资源，保障 VIP 用户的优先级

Spring Cloud Gateway 内置了基于 **Redis 令牌桶算法**的限流功能

**1️⃣ 添加 Redis 依赖**

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis-reactive</artifactId>
</dependency>
```

**2️⃣ 配置限流规则**

```yaml
spring:
  cloud:
    gateway:
      routes:
        - id: order-service
          uri: lb://order-service
          predicates:
            - Path=/orders/**
          filters:
            - name: RequestRateLimiter
              args:
                redis-rate-limiter.replenishRate: 10  # 每秒补充 10 个令牌
                redis-rate-limiter.burstCapacity: 20  # 允许的最大突发流量
                key-resolver: "#{@apiKeyResolver}"  # 限流的 key 规则
```

**3️⃣ 自定义 Key 解析器**

```java
@Bean
KeyResolver userKeyResolver() {
    return exchange -> Mono.just(exchange.getRequest().getRemoteAddress().getHostName());
}
```

👉 这样，每个 IP 地址每秒最多只能访问 10 次 API，超出后会被限流

| 特性     | 熔断（Circuit Breaker） | 限流（Rate Limiting）       |
| -------- | ----------------------- | --------------------------- |
| 目的     | 保护服务，防止雪崩      | 保护系统，防止过载          |
| 触发条件 | 远程服务故障率高        | 访问量超出限制              |
| 作用     | 暂停访问故障服务        | 限制请求速率                |
| 适用场景 | 微服务间调用            | API 网关、秒杀活动          |
| 实现工具 | Resilience4J、Hystrix   | Spring Cloud Gateway、Redis |

### 熔断 VS. 限流

什么时候使用熔断？什么时候使用限流？

- 熔断：当你调用的**远程服务变慢或崩溃**时，防止请求继续堆积导致整个系统挂掉
- 限流：当你的服务**流量暴增**时，防止服务器资源被耗尽

现实案例

- 淘宝双十一：高并发**限流**，防止流量冲垮系统
- 微信支付：如果支付接口故障，启用**熔断**，显示“支付系统繁忙”

**总结**

- 熔断用于**保护服务**，防止雪崩效应
- 限流用于**平稳流量**，防止高并发拖垮系统
- **Spring Cloud Resilience4J** 提供**熔断**机制，**Spring Cloud Gateway** 提供**限流**功能

当然了，也可以用阿里的开源中间件 Seatinel 实现限流熔断，方法多种多样

## Redis 集群同步

### 主从架构如何避免脏读

在 Redis 主从架构中：

- **主节点**：负责处理写操作（如 SET、DEL），并将写操作同步到从节点
- **从节点**：负责处理读操作（如 GET），并提供数据的副本

可以参考 Eureka 集群和 Zookeeper 集群的设计，感觉是差不多的（同属于 NoSQL）：主节点负责写，通过**复制**将数据同步到副节点，而副节点只负责数据的读取

这里的复制加粗了，为什么呢？因为在 Eureka 中是异步复制，而 Zookeeper 中是同步复制，这造就了二者**一致性**的差别，前者是 AP 系统，而后者是 CP 系统

在 Redis 集群中，这样的复制和 Eureka 一样，属于异步复制

- 由于主从同步是异步的，写操作在主节点完成后，并不会立即同步到从节点。因此，在同步完成之前，从节点可能会返回旧数据，导致**脏读**

一个很经典的避免脏读的方法：**读写锁**（写时禁止读）

这样会有很多局限性，存在以下问题：

1. **性能瓶颈**：写操作期间禁止读操作，会导致读请求被阻塞，降低系统的并发性能
2. **系统卡住**：如果主节点的写 I/O 阻塞，整个系统可能会卡住，影响可用性
3. **复杂性**：实现**分布式读写锁**会增加系统的复杂性

主从结构下，避免脏读除了读写锁还有什么方法呢？（天美 /(ㄒoㄒ)/~~）

4️⃣ 强制读主节点

对于敏感数据，强制性的让用户只能读取主节点内容，由于 Redis 是单线程的原子操作，单独读写一个节点，当然不会发生脏读啦

随之而来的是主节点负担增加，从而拖慢读写性能

1️⃣ 写后同步等待

刚刚提到，用读写锁，实际上是分布式锁的一种应用，这与“写后同步等待”不同，“写后同步等待”实际上就类似于 Eureka 的同步复制机制，主节点写完后对所有副节点进行阻塞的同步更新，更新完成后，才可以执行读操作

这可以使用 Redis 的 Wait 命令实现

```sh
SET key value
WAIT 1 1000  # 等待至少 1 个从节点同步完成，超时时间为 1000 毫秒
```

2️⃣ 版本号或时间戳机制

原理：为每个键（Key）添加版本号或时间戳，客户端在读取数据时检查版本号或时间戳，确保读取的是最新数据

优点

- 不需要阻塞读操作，性能较高
- 可以灵活控制数据的一致性级别

缺点

- 需要在客户端实现额外的逻辑
- 增加了数据存储的开销（多一个存储字段）

实现方式

在写操作时，更新键的版本号或时间戳

```sh
SET key:version 1
SET key:value "data"
```

在读操作时，检查版本号或时间戳

```sh
GET key:version
GET key:value
```

这里的读是指一次事务中的前后两次读（脏读的本质），在后一次做一个版本的检查，比如刚进入时读一次数据（这个数据上带一个版本号，或时间戳），然后在退出函数时再读一次，若版本号不同，则按后一次读出的数据为准

3️⃣ 最终一致性容忍

原理：接受一定时间内的脏读，通过业务逻辑容忍最终一致性

优点

- 性能最高，没有额外的同步开销
- 适合对一致性要求不高的场景

缺点：不适用于对一致性要求严格的场景（如金融交易）

实现方式：在业务逻辑中处理脏读问题，例如

- 对脏读不敏感的数据（如用户昵称、文章内容）可以直接使用从节点读取
- 对脏读敏感的数据（如余额、库存）可以从主节点读取

**注意，我们可以强制用户在主节点上读取数据，这样可以保证不会出现脏读，代价是主节点负担较大**，所以这里的实现采取了折中的方案，敏感数据限定读主节点，非敏感数据读副节点

那么“最终一致性容忍”是个什么情况呢，允许了一部分的脏读，但换回了相当一部分的性能

### 限流算法

令牌桶算法、漏桶算法、固定窗口算法、滑动窗口算法以及动态限流算法

- 令牌桶：每秒给多少令牌，同时给定令牌上限，令牌用完了拒绝请求
- 漏桶：每秒处理多少个水滴（请求），类似于消息队列的方式，每秒消费多少个请求
- 固定窗口：固定时间窗口，每个窗口通过的请求有限
- 滑动窗口：细粒的划分时间，在每个大窗口中控制小窗口，并可以通过小窗口的状态判断大窗口的访问控制，详见示例
- 动态限流：根据系统负载动态调节漏桶的流速，负载越高，流速越小

不同算法的异同

| 算法         | 原理                                                         | 优点                                                         | 缺点                                                         | 适用场景                                         | 示例                                                         |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------ | ------------------------------------------------------------ |
| 令牌桶算法   | 系统以固定的速率向桶中添加令牌（Token），桶的容量是固定的。 每个请求需要从桶中获取一个令牌，如果桶中有足够的令牌，则允许请求通过；否则拒绝请求。 如果桶满了，新生成的令牌会被丢弃 | 可以应对突发流量，因为桶中的令牌可以累积。 限流速率平滑，适合需要控制平均速率的场景 | 实现相对复杂，需要维护令牌桶的状态。 突发流量可能导致短时间内大量请求通过 | 需要平滑限流的场景，如 API 网关、流量控制        | 假设桶的容量为 10，每秒生成 2 个令牌。 如果桶中有 5 个令牌，同时有 8 个请求到达，则前 5 个请求可以通过，后 3 个请求被拒绝 |
| 漏桶算法     | 请求像水一样流入漏桶，漏桶以固定的速率处理请求（漏水）。 如果桶满了，新的请求会被丢弃或排队等待 | 限流速率非常平滑，适合需要严格控制请求速率的场景。 实现简单，容易理解 | 无法应对突发流量，即使桶中有空闲容量，请求也只能以固定速率通过。 可能导致请求的延迟增加 | 需要严格控制请求速率的场景，如消息队列、任务调度 | 假设漏桶的容量为 10，处理速率为每秒 2 个请求。 如果桶中有 5 个请求，同时有 8 个请求到达，则前 5 个请求可以进入桶中，后 3 个请求被拒绝。 桶中的请求以每秒 2 个的速率被处理 |
| 固定窗口算法 | 将时间划分为固定的窗口（如 1 秒），每个窗口内允许通过的请求数量是固定的。 如果窗口内的请求数量超过限制，则拒绝多余的请求 | 实现简单，容易理解。 适合对限流精度要求不高的场景            | 无法应对窗口边界处的突发流量。例如，如果窗口大小为 1 秒，限制为 100 个请求，则可能在窗口的最后 100ms 内收到 100 个请求，而在下一个窗口的前 100ms 内又收到 100 个请求，导致实际通过的请求数量是限制的两倍。 限流不够平滑 | 对限流精度要求不高的场景，如简单的 API 限流      | 假设窗口大小为 1 秒，限制为 100 个请求。 如果在 1 秒内收到 120 个请求，则前 100 个请求可以通过，后 20 个请求被拒绝 |
| 滑动窗口算法 | 将时间划分为多个小窗口（如 100ms），每个小窗口内允许通过的请求数量是固定的。 通过滑动窗口的方式动态计算当前时间窗口内的请求数量，如果超过限制，则拒绝多余的请求 | 比固定窗口算法更精确，能够更好地应对突发流量。 限流更加平滑  | 实现相对复杂，需要维护滑动窗口的状态。 计算开销较大          | 对限流精度要求较高的场景，如高并发 API 限流      | 假设窗口大小为 1 秒，划分为 10 个小窗口，每个小窗口的限制为 10 个请求。 如果在当前时间窗口内已经收到 90 个请求，则新的请求会被拒绝 |
| 动态限流算法 | 根据系统的实时负载动态调整限流速率。 例如，当系统负载较高时，降低限流速率；当系统负载较低时，提高限流速率 | 能够根据系统状态动态调整限流策略，更加灵活。 适合负载波动较大的场景 | 实现复杂，需要实时监控系统状态。 调整限流速率的策略需要精心设计 | 负载波动较大的场景，如电商大促、秒杀活动         | 假设系统负载超过 80% 时，将限流速率从每秒 100 个请求降低到每秒 50 个请求 |

限流算法的选择

- 如果需要平滑限流并支持突发流量，选择**令牌桶算法**
- 如果需要严格控制请求速率，选择**漏桶算法**
- 如果对限流精度要求不高，选择**固定窗口算法**或**计数器算法**
- 如果对限流精度要求较高，选择**滑动窗口算法**
- 如果需要根据系统状态动态调整限流策略，选择**动态限流算法**

### 缓存穿透、击穿和雪崩

充当缓存是 Redis 的主要功能之一，既然作为缓存，就面临穿透、击穿和雪崩的问题（所谓缓存三兄弟）

- 主要问题是如何避免以及发生了如何挽救